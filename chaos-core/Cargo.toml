[package]
name = "chaos-core"
version.workspace = true
edition.workspace = true
rust-version.workspace = true
description = "Core business logic for chaos-seed (subtitle + danmaku)."
license.workspace = true

[dependencies]
base64 = "0.22"
bytes = "1"
# ONNX runtime (pure Rust).
# Note: CosyVoice packs can be complex; we keep tract as a fallback backend.
candle-core = { version = "0.8", optional = true }
candle-onnx = { version = "0.8", optional = true }
dirs = "6"
fastrand = "2"
flate2 = "1"
# ----- voice chat / tts -----
futures = "0.3"
futures-util = "0.3"
hex = "0.4"
hound = "3"
image = { version = "0.25", default-features = false, features = ["png"] }
md5 = "0.7"
ndarray = { version = "0.15.6", optional = true }
# ONNX Runtime (onnxruntime.dll). Used as a robust backend for large LLM ONNX graphs.
# CUDA EP 通过 feature `onnx-ort-cuda` 显式开启，避免默认下载/打包 GPU 依赖。
ort = { version = "=2.0.0-rc.9", optional = true }
# Pin ort-sys to match silero-vad-rs's ort (=2.0.0-rc.9) to avoid ort/ort-sys API mismatches.
ort-sys = { version = "=2.0.0-rc.9", optional = true }
prost = "0.13"
prost-derive = "0.13"
qrcode = "0.14"
rand = "0.8"
rand_chacha = "0.3"
regex = "1"
# Enable gzip/brotli decoding: some upstream APIs (e.g. Huya) may return compressed bodies even when we don't request it.
reqwest = { version = "0.12", default-features = false, features = [
  "brotli",
  "cookies",
  "deflate",
  "gzip",
  "json",
  "rustls-tls",
  "stream"
] }
rsa = { version = "0.9", features = ["pem"] }
rubato = "0.16"
rustls = { version = "0.23", features = ["tls12"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
sha2 = "0.10"
silero-vad-rs = { version = "0.1.2", optional = true }
strsim = "0.11"
thiserror = "1"
tokenizers = { version = "0.21", default-features = false, features = ["onig"] }
tokio = { version = "1", features = [
  "fs",
  "io-util",
  "macros",
  "net",
  "process",
  "rt-multi-thread",
  "sync",
  "time"
] }
tokio-stream = "0.1"
tokio-tungstenite = { version = "0.28.0", default-features = false, features = [
  "connect",
  "native-tls-vendored",
  "url"
] }
tokio-util = "0.7"
tracing = "0.1"
tract-core = { version = "0.23.0-dev.2", optional = true }
tract-hir = { version = "0.23.0-dev.2", optional = true }
tract-onnx = { version = "0.23.0-dev.2", optional = true }
url = "2"
urlencoding = "2"

# CosyVoice3 路线2：纯 Rust + Candle 推理（参考 cosyvoice3.rs）
# 说明：为了不影响现有 `onnx-candle`（candle 0.8）依赖，这里使用 crate alias 引入另一套 candle 版本（git rev）。
cv3-candle-core = { package = "candle-core", git = "https://github.com/SpenserCai/candle", rev = "6058747", optional = true }
cv3-candle-nn = { package = "candle-nn", git = "https://github.com/SpenserCai/candle", rev = "6058747", optional = true }
cv3-candle-transformers = { package = "candle-transformers", git = "https://github.com/SpenserCai/candle", rev = "6058747", optional = true }
cv3-candle-onnx = { package = "candle-onnx", git = "https://github.com/SpenserCai/candle", rev = "6058747", optional = true }

[dev-dependencies]
chaos-proto = { path = "../chaos-proto" }
httpmock = "0.7"
tempfile = "3"

[target.'cfg(windows)'.dependencies]
windows = { version = "0.62", features = [
  "Foundation",
  "Media_Control",
  "Storage_Streams"
] }

[features]
default = ["onnx-ort"]
live-tests = []
onnx-candle = ["dep:candle-core", "dep:candle-onnx"]
onnx-ort = ["dep:ort"]
onnx-ort-cuda = ["onnx-ort", "ort/cuda"]
onnx-tract = ["dep:tract-core", "dep:tract-hir", "dep:tract-onnx"]
silero-vad = ["dep:ndarray", "dep:ort-sys", "dep:silero-vad-rs"]

# Route2：CosyVoice3 Candle 推理（LLM + Flow + HiFT）
cosyvoice3-candle = [
  "dep:cv3-candle-core",
  "dep:cv3-candle-nn",
  "dep:cv3-candle-transformers",
]
# Route2：使用 ONNX frontend 提取 prompt features（campplus + speech_tokenizer_v3）
cosyvoice3-candle-onnx = [
  "cosyvoice3-candle",
  "dep:cv3-candle-onnx",
  "cv3-candle-transformers/onnx",
]
